## ðŸš€ About the Project  
This project aims to **make video content accessible to the deaf community** by converting speech into **sign language animations**. It uses **AI-powered models** for **Speech-to-Text (STT)** and **Text-to-Sign (TTS)** translation.

## âœ¨ Features  
âœ… Converts video speech to **text** using **Whisper STT**  
âœ… Generates **sign language videos** from text  
âœ… AI-powered **sign language translation**  
âœ… Easy integration with browser extensions  

---

## ðŸ›  Tech Stack  
- **Backend:** FastAPI, Python  
- **AI Models:** Whisper STT, Custom TTS  
- **Frontend:** JavaScript (if applicable)  
- **Other Tools:** FFmpeg, OpenAI Whisper  

---
## ðŸ“‚ Project Structure  
sign-language-project/ â”‚â”€â”€ api/ # API endpoints (FastAPI) â”‚â”€â”€ extension/ # Browser extension files (if any) â”‚â”€â”€ sign_language_data/ # Dataset & models â”‚ â”œâ”€â”€ datasets/ # Training data â”‚ â”œâ”€â”€ models/ # Pretrained models & scripts â”‚ â”œâ”€â”€ stt.py # Speech-to-Text script â”‚ â”œâ”€â”€ tts.py # Text-to-Sign script â”‚â”€â”€ preprocessing/ # Data preprocessing scripts â”‚â”€â”€ utils/ # Utility functions â”‚â”€â”€ transcription.txt # Extracted text from STT â”‚â”€â”€ test_video.mp4 # Sample test video â”‚â”€â”€ generate_translation.py # Main translation script â”‚â”€â”€ README.md # Project documentation â”‚â”€â”€ requirements.txt # Python dependencies â”‚â”€â”€ venv/ # Virtual environment

## ðŸ”¥ Installation & Setup  

### ðŸ–¥ Prerequisites  
- **Python 3.9+**
- **FFmpeg installed** (Download from [FFmpeg](https://ffmpeg.org/download.html))
- **Virtual Environment** (recommended)

### ðŸš€ Steps to Run  
```bash
# Clone the repository
git clone https://github.com/your-username/sign-language-accessibility.git
cd sign-language-accessibility

# Create and activate virtual environment
python -m venv venv
source venv/bin/activate   # For macOS/Linux
venv\Scripts\activate      # For Windows

# Install dependencies
pip install -r requirements.txt

# Run the speech-to-text script
python sign_language_data/models/stt.py --video test_video.mp4

# Run the text-to-sign model
python sign_language_data/models/tts.py --input transcription.txt

# Run the main translation script
python generate_translation.py test_video.mp4
